{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea78940-30e4-448d-89c1-a11da1c03cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65e07d2-2332-42f2-abfc-c07a8f0dda4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_set: ['<pad>', 'n', 's', 'm', 'h', 'd', 'g', 'l', 'o', 't', 'c', 'p', ' ', 'e', 'w', 'i', 'u', 'r', 'a']\n",
      "char_set length: 19\n"
     ]
    }
   ],
   "source": [
    "# Random word from random word generator\n",
    "data = ['hello world',\n",
    "        'midnight',\n",
    "        'calculation',\n",
    "        'path',\n",
    "        'short circuit']\n",
    "\n",
    "# Make dictionary\n",
    "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
    "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
    "print('char_set:', char_set)\n",
    "print('char_set length:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6459e37d-913e-434d-8b56-57c8da2bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 13,  7,  7,  8, 12, 14,  8, 17,  7,  5])\n",
      "tensor([ 3, 15,  5,  1, 15,  6,  4,  9])\n",
      "tensor([10, 18,  7, 10, 16,  7, 18,  9, 15,  8,  1])\n",
      "tensor([11, 18,  9,  4])\n",
      "tensor([ 2,  4,  8, 17,  9, 12, 10, 15, 17, 10, 16, 15,  9])\n"
     ]
    }
   ],
   "source": [
    "# Convert character to index and make list of tensors\n",
    "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in X:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8def912-8315-4594-85d2-099d1599c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths: [11, 8, 11, 4, 13]\n"
     ]
    }
   ],
   "source": [
    "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
    "lengths = [len(seq) for seq in X]\n",
    "print('lengths:', lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce96adc8-c367-4c6a-8bdb-7351e8852e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4, 13,  7,  7,  8, 12, 14,  8, 17,  7,  5,  0,  0],\n",
      "        [ 3, 15,  5,  1, 15,  6,  4,  9,  0,  0,  0,  0,  0],\n",
      "        [10, 18,  7, 10, 16,  7, 18,  9, 15,  8,  1,  0,  0],\n",
      "        [11, 18,  9,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  4,  8, 17,  9, 12, 10, 15, 17, 10, 16, 15,  9]])\n",
      "torch.Size([5, 13])\n"
     ]
    }
   ],
   "source": [
    "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
    "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b1c524-2a9a-41ce-959e-6ed658fa53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4,  8, 17,  9, 12, 10, 15, 17, 10, 16, 15,  9])\n",
      "tensor([ 4, 13,  7,  7,  8, 12, 14,  8, 17,  7,  5])\n",
      "tensor([10, 18,  7, 10, 16,  7, 18,  9, 15,  8,  1])\n",
      "tensor([ 3, 15,  5,  1, 15,  6,  4,  9])\n",
      "tensor([11, 18,  9,  4])\n"
     ]
    }
   ],
   "source": [
    "# Sort by descending lengths\n",
    "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
    "sorted_X = [X[idx] for idx in sorted_idx]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in sorted_X:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd62309-2ac7-4a31-a000-62d0d5d6d54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([ 2,  4, 10,  3, 11,  4, 13, 18, 15, 18,  8,  7,  7,  5,  9, 17,  7, 10,\n",
      "         1,  4,  9,  8, 16, 15, 12, 12,  7,  6, 10, 14, 18,  4, 15,  8,  9,  9,\n",
      "        17, 17, 15, 10,  7,  8, 16,  5,  1, 15,  9]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "packed_sequence = pack_sequence(sorted_X)\n",
    "print(packed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11ca13c-d5d2-4775-8399-6763642ecc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n"
     ]
    }
   ],
   "source": [
    "# one-hot embedding using PaddedSequence\n",
    "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
    "embedded_tensor = eye[padded_sequence]\n",
    "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f180ebe4-7894-4cf4-81d6-e424bd522ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n"
     ]
    }
   ],
   "source": [
    "# one-hot embedding using PackedSequence\n",
    "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
    "print(embedded_packed_seq.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5dcae4-d7c0-4a95-b87c-9f528753fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare RNN\n",
    "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad5d695f-f16a-4727-aefb-e08a0ded663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 30])\n",
      "torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_tensor)\n",
    "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
    "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e09775-7ff6-4850-8c63-9ee13631e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 30])\n",
      "torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_packed_seq)\n",
    "print(rnn_output.data.shape)\n",
    "print(hidden.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe593ce-ea7b-46a3-a1fb-7dbbc211606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n",
      "tensor([13, 11, 11,  8,  4])\n"
     ]
    }
   ],
   "source": [
    "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
    "print(unpacked_sequence.shape)\n",
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94dee1ba-a94a-4f73-a14b-9ed6a6e93f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n"
     ]
    }
   ],
   "source": [
    "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
    "print(embedded_padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4e6ed0-ffdd-47e1-9095-149e07ff9ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n",
      "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "sorted_lengths = sorted(lengths, reverse=True)\n",
    "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
    "print(new_packed_sequence.data.shape)\n",
    "print(new_packed_sequence.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39891ee-8bfd-4ae6-b3bc-8afcfc55127d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
